diff --git a/src/llama.cpp b/src/llama.cpp
index e0fe8013..268246ac 100644
--- a/src/llama.cpp
+++ b/src/llama.cpp
@@ -14713,6 +14713,16 @@ static int llama_decode_internal(
 
         ggml_cgraph * gf = llama_build_graph(lctx, u_batch, false);
 
+        static int graphs_printed = 0;
+
+        if (graphs_printed < 10) {
+            ggml_graph_print   (gf);
+            char buf[] = "graph0.dot";
+            buf[5] += graphs_printed;
+            ggml_graph_dump_dot(gf, NULL, buf);
+            graphs_printed++;
+        }
+
         // the output is always the last tensor in the graph
         struct ggml_tensor * res  = gf->nodes[gf->n_nodes - 1];
         struct ggml_tensor * embd = gf->nodes[gf->n_nodes - 2];
